{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_LSTM_kernel_size_3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for numpy\n",
    "np.random.seed(11)\n",
    "# Set random seed for pytorch\n",
    "torch.manual_seed(11)\n",
    "# Set random seed for pytorch running in GPU\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USC_train_features = np.load(\"usc_multi/train_features_USC_mod_al.npy\") ### <- change file path\n",
    "USC_test_features = np.load(\"usc_multi/test_features_USC_mod_al.npy\")\n",
    "USC_train_labels = np.load(\"usc_multi/train_labels_USC_mod_al.npy\")\n",
    "USC_test_labels = np.load(\"usc_multi/test_labels_USC_mod_al.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 15\n",
    "batch_size = 10\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "USC_train_labels = USC_train_labels.astype(int) - 1\n",
    "USC_test_labels = USC_test_labels.astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to torch tensor\n",
    "tensor_USC_train_features = torch.Tensor(USC_train_features) \n",
    "tensor_USC_train_labels = torch.Tensor(USC_train_labels)\n",
    "tensor_USC_test_features = torch.Tensor(USC_test_features) \n",
    "tensor_USC_test_labels = torch.Tensor(USC_test_labels)\n",
    "# Add one dimension of channel\n",
    "tensor_USC_train_features = torch.unsqueeze(tensor_USC_train_features, 1)\n",
    "tensor_USC_test_features = torch.unsqueeze(tensor_USC_test_features, 1)\n",
    "# Create datset\n",
    "train_dataset_USC = TensorDataset(tensor_USC_train_features,tensor_USC_train_labels)\n",
    "test_dataset_USC = TensorDataset(tensor_USC_test_features,tensor_USC_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset_USC, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset_USC, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 18, 384])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for image,label in train_loader:\n",
    "    print(image.size())\n",
    "    print(label.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.rand(10,32,9,192)\n",
    "mod =  nn.Conv2d(32,64, kernel_size=3, stride=1, padding=1)\n",
    "out = mod(inputs)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.rand(10,32,9,192)\n",
    "print(inputs.view(10,128,-1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cnn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32, kernel_size=3, stride=1, padding=1)  ### 10,32,18,384\n",
    "        self.pool = nn.MaxPool2d(2, 2) ### 10,32,9,192 2nd layer\n",
    "        self.conv2 = nn.Conv2d(32,64, kernel_size=3, stride=1, padding=1) ###10,64,9,192 3rd layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch,c,h,w = x.size()\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = (F.relu(self.conv2(x))) ### 10,64,9,192/ 5,64,9,192\n",
    "        x = x.view(batch,-1) ### 10,110592 \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN_LSTM(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(CNN_LSTM, self).__init__() ###(num_samples,timesteps,input_dim). \n",
    "        self.cnn = Cnn()\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=864, ### [32 <- 216] / [64<-432]/ [128<-864] or single [32 <- 72] / [64<-144]/ [128<-288]\n",
    "            hidden_size=144, \n",
    "            num_layers=3, ### change [1,3,5]\n",
    "            batch_first=True)\n",
    "        self.linear = nn.Linear(144,12)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch,c,h,w = x.size()\n",
    "        c_out = self.cnn(x) ### 10,110592\n",
    "        r_in = c_out.view(batch,128,-1) ### 10,1,8192\n",
    "        r_out, (h_n, h_c) = self.rnn(r_in)\n",
    "        r_out2 = self.linear(r_out[:, -1, :])\n",
    "        return F.log_softmax(r_out2, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose CPU or GPU\n",
    "# model = ConvNet() #CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN_LSTM().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Step [100/3073], Loss: 2.2222, Accuracy: 20.00%\n",
      "Epoch [1/15], Step [200/3073], Loss: 2.0125, Accuracy: 10.00%\n",
      "Epoch [1/15], Step [300/3073], Loss: 1.2799, Accuracy: 60.00%\n",
      "Epoch [1/15], Step [400/3073], Loss: 1.6343, Accuracy: 40.00%\n",
      "Epoch [1/15], Step [500/3073], Loss: 0.7822, Accuracy: 90.00%\n",
      "Epoch [1/15], Step [600/3073], Loss: 1.4112, Accuracy: 50.00%\n",
      "Epoch [1/15], Step [700/3073], Loss: 1.3680, Accuracy: 30.00%\n",
      "Epoch [1/15], Step [800/3073], Loss: 1.3265, Accuracy: 30.00%\n",
      "Epoch [1/15], Step [900/3073], Loss: 1.3306, Accuracy: 50.00%\n",
      "Epoch [1/15], Step [1000/3073], Loss: 1.0240, Accuracy: 60.00%\n",
      "Epoch [1/15], Step [1100/3073], Loss: 1.2268, Accuracy: 70.00%\n",
      "Epoch [1/15], Step [1200/3073], Loss: 1.2545, Accuracy: 60.00%\n",
      "Epoch [1/15], Step [1300/3073], Loss: 0.9139, Accuracy: 60.00%\n",
      "Epoch [1/15], Step [1400/3073], Loss: 1.3785, Accuracy: 50.00%\n",
      "Epoch [1/15], Step [1500/3073], Loss: 0.7404, Accuracy: 90.00%\n",
      "Epoch [1/15], Step [1600/3073], Loss: 1.2002, Accuracy: 40.00%\n",
      "Epoch [1/15], Step [1700/3073], Loss: 1.0055, Accuracy: 60.00%\n",
      "Epoch [1/15], Step [1800/3073], Loss: 1.3385, Accuracy: 40.00%\n",
      "Epoch [1/15], Step [1900/3073], Loss: 1.7782, Accuracy: 30.00%\n",
      "Epoch [1/15], Step [2000/3073], Loss: 1.2452, Accuracy: 50.00%\n",
      "Epoch [1/15], Step [2100/3073], Loss: 0.7075, Accuracy: 70.00%\n",
      "Epoch [1/15], Step [2200/3073], Loss: 0.8589, Accuracy: 50.00%\n",
      "Epoch [1/15], Step [2300/3073], Loss: 1.1085, Accuracy: 50.00%\n",
      "Epoch [1/15], Step [2400/3073], Loss: 1.6679, Accuracy: 20.00%\n",
      "Epoch [1/15], Step [2500/3073], Loss: 1.0800, Accuracy: 50.00%\n",
      "Epoch [1/15], Step [2600/3073], Loss: 1.6053, Accuracy: 30.00%\n",
      "Epoch [1/15], Step [2700/3073], Loss: 0.5880, Accuracy: 70.00%\n",
      "Epoch [1/15], Step [2800/3073], Loss: 0.6642, Accuracy: 60.00%\n",
      "Epoch [1/15], Step [2900/3073], Loss: 1.0023, Accuracy: 50.00%\n",
      "Epoch [1/15], Step [3000/3073], Loss: 0.8888, Accuracy: 60.00%\n",
      "Epoch [2/15], Step [100/3073], Loss: 0.5796, Accuracy: 80.00%\n",
      "Epoch [2/15], Step [200/3073], Loss: 0.9037, Accuracy: 70.00%\n",
      "Epoch [2/15], Step [300/3073], Loss: 0.4456, Accuracy: 90.00%\n",
      "Epoch [2/15], Step [400/3073], Loss: 0.6557, Accuracy: 70.00%\n",
      "Epoch [2/15], Step [500/3073], Loss: 0.5568, Accuracy: 70.00%\n",
      "Epoch [2/15], Step [600/3073], Loss: 0.8978, Accuracy: 80.00%\n",
      "Epoch [2/15], Step [700/3073], Loss: 0.8851, Accuracy: 70.00%\n",
      "Epoch [2/15], Step [800/3073], Loss: 0.5610, Accuracy: 80.00%\n",
      "Epoch [2/15], Step [900/3073], Loss: 1.7069, Accuracy: 10.00%\n",
      "Epoch [2/15], Step [1000/3073], Loss: 0.8030, Accuracy: 70.00%\n",
      "Epoch [2/15], Step [1100/3073], Loss: 0.5376, Accuracy: 100.00%\n",
      "Epoch [2/15], Step [1200/3073], Loss: 0.6643, Accuracy: 70.00%\n",
      "Epoch [2/15], Step [1300/3073], Loss: 1.4498, Accuracy: 30.00%\n",
      "Epoch [2/15], Step [1400/3073], Loss: 0.6772, Accuracy: 90.00%\n",
      "Epoch [2/15], Step [1500/3073], Loss: 0.6870, Accuracy: 80.00%\n",
      "Epoch [2/15], Step [1600/3073], Loss: 0.6297, Accuracy: 70.00%\n",
      "Epoch [2/15], Step [1700/3073], Loss: 1.0080, Accuracy: 40.00%\n",
      "Epoch [2/15], Step [1800/3073], Loss: 0.8408, Accuracy: 60.00%\n",
      "Epoch [2/15], Step [1900/3073], Loss: 0.9709, Accuracy: 70.00%\n",
      "Epoch [2/15], Step [2000/3073], Loss: 0.9311, Accuracy: 60.00%\n",
      "Epoch [2/15], Step [2100/3073], Loss: 0.4520, Accuracy: 80.00%\n",
      "Epoch [2/15], Step [2200/3073], Loss: 1.1678, Accuracy: 60.00%\n",
      "Epoch [2/15], Step [2300/3073], Loss: 1.1351, Accuracy: 60.00%\n",
      "Epoch [2/15], Step [2400/3073], Loss: 2.2337, Accuracy: 50.00%\n",
      "Epoch [2/15], Step [2500/3073], Loss: 0.9012, Accuracy: 60.00%\n",
      "Epoch [2/15], Step [2600/3073], Loss: 0.6040, Accuracy: 90.00%\n",
      "Epoch [2/15], Step [2700/3073], Loss: 0.8057, Accuracy: 60.00%\n",
      "Epoch [2/15], Step [2800/3073], Loss: 0.8630, Accuracy: 70.00%\n",
      "Epoch [2/15], Step [2900/3073], Loss: 0.5304, Accuracy: 70.00%\n",
      "Epoch [2/15], Step [3000/3073], Loss: 1.0322, Accuracy: 60.00%\n",
      "Epoch [3/15], Step [100/3073], Loss: 1.0797, Accuracy: 50.00%\n",
      "Epoch [3/15], Step [200/3073], Loss: 0.5090, Accuracy: 90.00%\n",
      "Epoch [3/15], Step [300/3073], Loss: 1.1002, Accuracy: 50.00%\n",
      "Epoch [3/15], Step [400/3073], Loss: 1.0627, Accuracy: 50.00%\n",
      "Epoch [3/15], Step [500/3073], Loss: 0.9769, Accuracy: 40.00%\n",
      "Epoch [3/15], Step [600/3073], Loss: 1.7121, Accuracy: 40.00%\n",
      "Epoch [3/15], Step [700/3073], Loss: 0.5758, Accuracy: 70.00%\n",
      "Epoch [3/15], Step [800/3073], Loss: 0.4998, Accuracy: 70.00%\n",
      "Epoch [3/15], Step [900/3073], Loss: 0.7778, Accuracy: 70.00%\n",
      "Epoch [3/15], Step [1000/3073], Loss: 0.9519, Accuracy: 80.00%\n",
      "Epoch [3/15], Step [1100/3073], Loss: 0.3854, Accuracy: 90.00%\n",
      "Epoch [3/15], Step [1200/3073], Loss: 0.8116, Accuracy: 70.00%\n",
      "Epoch [3/15], Step [1300/3073], Loss: 0.9047, Accuracy: 70.00%\n",
      "Epoch [3/15], Step [1400/3073], Loss: 0.8318, Accuracy: 70.00%\n",
      "Epoch [3/15], Step [1500/3073], Loss: 0.7267, Accuracy: 70.00%\n",
      "Epoch [3/15], Step [1600/3073], Loss: 0.9700, Accuracy: 70.00%\n",
      "Epoch [3/15], Step [1700/3073], Loss: 0.9754, Accuracy: 70.00%\n",
      "Epoch [3/15], Step [1800/3073], Loss: 0.9266, Accuracy: 70.00%\n",
      "Epoch [3/15], Step [1900/3073], Loss: 0.6376, Accuracy: 80.00%\n",
      "Epoch [3/15], Step [2000/3073], Loss: 1.2324, Accuracy: 60.00%\n",
      "Epoch [3/15], Step [2100/3073], Loss: 0.5948, Accuracy: 80.00%\n",
      "Epoch [3/15], Step [2200/3073], Loss: 1.0708, Accuracy: 50.00%\n",
      "Epoch [3/15], Step [2300/3073], Loss: 0.9860, Accuracy: 50.00%\n",
      "Epoch [3/15], Step [2400/3073], Loss: 0.4594, Accuracy: 90.00%\n",
      "Epoch [3/15], Step [2500/3073], Loss: 0.3286, Accuracy: 80.00%\n",
      "Epoch [3/15], Step [2600/3073], Loss: 0.5541, Accuracy: 70.00%\n",
      "Epoch [3/15], Step [2700/3073], Loss: 0.9009, Accuracy: 70.00%\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Run the forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels.to(device).long())\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('WALKING_F','WALKING_L','WALKING_R','WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS',\"Running_F\",\n",
    "           \"Jumping_up\",'SITTING', 'STANDING', 'Sleeping',\"Elevator_up\",\"Elevator_down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "# Test the model on GPU\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images.to(device))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_predictions.append(predicted)\n",
    "        all_labels.append(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the UCIHAR test images: {} %'.format((correct / total) * 100))\n",
    "\n",
    "mat = metrics.confusion_matrix(torch.cat(all_predictions).cpu(), torch.cat(all_labels).cpu())\n",
    "plt.figure(figsize=(7,7))\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
