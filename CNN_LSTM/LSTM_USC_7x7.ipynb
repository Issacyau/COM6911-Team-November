{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_LSTM_kernel_size_7x7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for numpy\n",
    "np.random.seed(11)\n",
    "# Set random seed for pytorch\n",
    "torch.manual_seed(11)\n",
    "# Set random seed for pytorch running in GPU\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USC_train_features = np.load(\"usc_multi/train_features_USC_mod_al.npy\")\n",
    "USC_test_features = np.load(\"usc_multi/test_features_USC_mod_al.npy\")\n",
    "USC_train_labels = np.load(\"usc_multi/train_labels_USC_mod_al.npy\")\n",
    "USC_test_labels = np.load(\"usc_multi/test_labels_USC_mod_al.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "USC_train_labels = USC_train_labels.astype(int) - 1\n",
    "USC_test_labels = USC_test_labels.astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to torch tensor\n",
    "tensor_USC_train_features = torch.Tensor(USC_train_features) \n",
    "tensor_USC_train_labels = torch.Tensor(USC_train_labels)\n",
    "tensor_USC_test_features = torch.Tensor(USC_test_features) \n",
    "tensor_USC_test_labels = torch.Tensor(USC_test_labels)\n",
    "# Add one dimension of channel\n",
    "tensor_USC_train_features = torch.unsqueeze(tensor_USC_train_features, 1)\n",
    "tensor_USC_test_features = torch.unsqueeze(tensor_USC_test_features, 1)\n",
    "# Create datset\n",
    "train_dataset_USC = TensorDataset(tensor_USC_train_features,tensor_USC_train_labels)\n",
    "test_dataset_USC = TensorDataset(tensor_USC_test_features,tensor_USC_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset_USC, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset_USC, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 18, 384])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for image,label in train_loader:\n",
    "    print(image.size())\n",
    "    print(label.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30725\n",
      "13169\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader.dataset))\n",
    "print(len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 64, 9, 192])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.rand(10,32,9,192)\n",
    "mod =  nn.Conv2d(32,64, kernel_size=7, stride=1, padding=3)\n",
    "out = mod(inputs)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 110592])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.rand(10,64,9,192)\n",
    "print(inputs.view(10,-1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cnn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32, kernel_size=7, stride=1, padding=3)  ### 10,32,18,384\n",
    "        self.pool = nn.MaxPool2d(2, 2) ### 10,32,9,192 2nd layer\n",
    "        self.conv2 = nn.Conv2d(32,64, kernel_size=7, stride=1, padding=3) ###10,64,9,192 3rd layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch,c,h,w = x.size()\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = (F.relu(self.conv2(x))) \n",
    "        x = x.view(batch,-1) ### 10,110592 \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN_LSTM(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(CNN_LSTM, self).__init__() ###(num_samples,timesteps,input_dim). \n",
    "        self.cnn = Cnn()\n",
    "        self.rnn = nn.LSTM( ###[batch_size, seq_len, nb_features] 4th layer\n",
    "            input_size=864, ### [32 <- 216] / [64<-432]/ [128<-864] or single [32 <- 72] / [64<-144]/ [128<-288]\n",
    "            hidden_size=144, \n",
    "            num_layers=5, ### <- change [1,3,5]\n",
    "            batch_first=True)\n",
    "        self.linear = nn.Linear(144,12)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch,c,h,w = x.size()\n",
    "        c_out = self.cnn(x) ### 10,110592\n",
    "        r_in = c_out.view(batch,128,-1) ### 10,110592 -> 10,128,864\n",
    "        r_out, (h_n, h_c) = self.rnn(r_in)\n",
    "        r_out2 = self.linear(r_out[:, -1, :])\n",
    "        return F.log_softmax(r_out2, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose CPU or GPU\n",
    "# model = ConvNet() #CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN_LSTM().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/3073], Loss: 2.5047, Accuracy: 0.00%\n",
      "Epoch [1/5], Step [200/3073], Loss: 2.4892, Accuracy: 20.00%\n",
      "Epoch [1/5], Step [300/3073], Loss: 2.4809, Accuracy: 20.00%\n",
      "Epoch [1/5], Step [400/3073], Loss: 2.4950, Accuracy: 10.00%\n",
      "Epoch [1/5], Step [500/3073], Loss: 2.4473, Accuracy: 20.00%\n",
      "Epoch [1/5], Step [600/3073], Loss: 2.5007, Accuracy: 0.00%\n",
      "Epoch [1/5], Step [700/3073], Loss: 2.4234, Accuracy: 0.00%\n",
      "Epoch [1/5], Step [800/3073], Loss: 2.3604, Accuracy: 20.00%\n",
      "Epoch [1/5], Step [900/3073], Loss: 2.1166, Accuracy: 20.00%\n",
      "Epoch [1/5], Step [1000/3073], Loss: 2.1246, Accuracy: 10.00%\n",
      "Epoch [1/5], Step [1100/3073], Loss: 2.0956, Accuracy: 20.00%\n",
      "Epoch [1/5], Step [1200/3073], Loss: 1.6426, Accuracy: 40.00%\n",
      "Epoch [1/5], Step [1300/3073], Loss: 1.8727, Accuracy: 40.00%\n",
      "Epoch [1/5], Step [1400/3073], Loss: 2.0527, Accuracy: 20.00%\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Run the forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels.to(device).long())\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('WALKING_F','WALKING_L','WALKING_R','WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS',\"Running_F\",\n",
    "           \"Jumping_up\",'SITTING', 'STANDING', 'Sleeping',\"Elevator_up\",\"Elevator_down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "# Test the model on GPU\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images.to(device))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_predictions.append(predicted)\n",
    "        all_labels.append(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the UCIHAR test images: {} %'.format((correct / total) * 100))\n",
    "\n",
    "mat = metrics.confusion_matrix(torch.cat(all_predictions).cpu(), torch.cat(all_labels).cpu())\n",
    "plt.figure(figsize=(7,7))\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
